\documentclass[12pt,a4paper]{report}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{pdfcomment}
\usepackage{lipsum} 
\usepackage{float} 
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{array} % Added for better table formatting
\usepackage{tocloft}

\titleformat{\chapter}[display]
  {\centering\huge\bfseries} % Center, large, and bold
  {\chaptername\ \thechapter}{20pt}{\huge}
% Add this to modify how unnumbered chapters appear in TOC
\usepackage{tocbibind}
% Set up page numbering options
% After loading fancyhdr package and before beginning document

% Redefine plain style to completely remove headers from chapter pages


% Configure lstlisting
\lstset{
    language=Python,
    breaklines=true,
    basicstyle=\small\ttfamily,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    showstringspaces=false
}

\begin{document}

\doublespacing

% Cover Page
% First Title Page
\begin{center}
    \textbf{\LARGE AI-DRIVEN FRAMEWORK FOR OPTIMIZING LOCAL BODY AND MP FUND MANAGEMENT} \\
    \vspace{12pt}
    
    Mini Project Report \\
    \vspace{12pt}
    
    \textit{Submitted in partial fulfillment of the requirements for \\ the award of degree of} \\
    \vspace{12pt}

    \textbf{BACHELOR OF TECHNOLOGY} \\
    \vspace{8pt}
    
    \textit{in} \\
    \vspace{8pt}
    
    \textbf{COMPUTER SCIENCE AND ENGINEERING} \\
    \vspace{8pt}
    
    \textit{of} \\
    \vspace{8pt}
    
    \textbf{APJ ABDUL KALAM TECHNOLOGICAL UNIVERSITY} \\
    \vspace{8pt}
    
    \textit{by} \\
    \vspace{8pt}

    \textbf{PAUL BINU (MAC22CD048)} \\  
    \vspace{8pt}
    
    \textbf{PAULU WILSON (MAC22CD049)} \\  
    \vspace{8pt}
    
    \textbf{RONAL SHOEY GEORGE (MAC22CD051)} \\  
    \vspace{8pt}

    \includegraphics{college_logo.png}
    \vspace{8pt}

    \textbf{Department of Computer Science \& Engineering \\
    Mar Athanasius College of Engineering (Autonomous)\\
    Kothamangalam} \\
    \vspace{8pt}
    \textbf{APRIL 2025} \\
\thispagestyle{empty}
\end{center}

% Second Title Page
\begin{center}
    \textbf{\LARGE AI-DRIVEN FRAMEWORK FOR OPTIMIZING LOCAL BODY AND MP FUND MANAGEMENT} \\
    \vspace{12pt}
    
    Mini Project Report \\
    \vspace{12pt}
    
    \textit{Submitted in partial fulfillment of the requirements for \\ the award of degree of} \\
    \vspace{12pt}

    \textbf{BACHELOR OF TECHNOLOGY} \\
    \vspace{8pt}
    
    \textit{in} \\
    \vspace{8pt}
    
    \textbf{COMPUTER SCIENCE AND ENGINEERING} \\
    \vspace{8pt}
    
    \textit{of} \\
    \vspace{8pt}
    
    \textbf{APJ ABDUL KALAM TECHNOLOGICAL UNIVERSITY} \\
    \vspace{8pt}
    
    \textit{by} \\
    \vspace{8pt}

    \textbf{PAUL BINU (MAC22CD048)} \\  
    \vspace{8pt}
    
    \textbf{PAULU WILSON (MAC22CD049)} \\  
    \vspace{8pt}
    
    \textbf{RONAL SHOEY GEORGE (MAC22CD051)} \\  
    \vspace{8pt}

    \includegraphics{college_logo.png}
    \vspace{8pt}

    \textbf{Department of Computer Science \& Engineering \\
    Mar Athanasius College of Engineering (Autonomous)\\
    Kothamangalam} \\
    \vspace{8pt}
    \textbf{APRIL 2025} \\
\thispagestyle{empty}
\end{center}

% Certificate Page
\thispagestyle{empty}
\begin{center}

    \textbf{DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\
    MAR ATHANASIUS COLLEGE OF ENGINEERING (Autonomous)\\
    KOTHAMANGALAM} 

    \vspace{20pt}

    \includegraphics{college_logo.png}
    \vspace{20pt}

    \textbf{CERTIFICATE} \\
    \vspace{20pt}
\end{center}
\justifying
\textit{This is to certify that the report entitled} \textbf{AI-DRIVEN FRAMEWORK FOR OPTIMIZING LOCAL BODY AND MP FUND MANAGEMENT }\textit{submitted by} \textbf{Paul Binu (MAC22CD048), Paulu Wilson (MAC22CD049), and Ronal Shoey George (MAC22CD051)}
 \textit{towards partial fulfillment of the requirement for the award of Degree of Bachelor of Technology in Computer Science and Engineering from APJ Abdul Kalam Technological University for APRIL 2025 is a bonafide record of the project carried out by them under our supervision and guidance.} \\  

\vspace{20pt}
\noindent \textbf{Prof. Sumi Joy} \hfill \textbf{Prof. Suzen Saju Kallungal} 

\noindent \textit{Project Guide} \hfill \textit{Project Coordinator}

\vspace{40pt}
\noindent \textbf{Internal Examiner(s)} \hfill \textbf{External Examiner(s)}


\vspace{40pt}
\noindent Date: \hfill Dept. Seal

\thispagestyle{empty}
\clearpage
\vspace{5cm}
\begin{center}
    
    \textbf{\filcenter\LARGE DECLARATION}
    \vspace{25pt}
\end{center}

We, undersigned, hereby declare that the project report Ai-Driven Framework for Optimizing Local Body and MP Fund Management for partial fulfillment of the requirements for the award of degree of Bachelor of Technology of the APJ Abdul Kalam Technological University, Kerala, is a bonafide work done by us under the supervision of Prof. Suzen Saju Kallungal. This submission represents the ideas in our own words, and where ideas or words of others have been included, we have adequately and accurately cited and referenced the original sources. We also declare that we have adhered to the ethics of academic honesty and integrity and have not misrepresented or fabricated any data, idea, fact, or source in our submission. We understand that any violation of the above will be a cause for disciplinary action by the institute or the University and can also evoke penal action from the sources that have not been properly cited or from whom proper permission has not been obtained. This report has not previously formed the basis for the award of any degree, diploma, or similar title of any other University.

\vspace{50pt}
\noindent Date: 28/03/2025 
\hfill  Paul Binu (MAC22CD048) \\ Kothamangalam
\hfill  Paulu Wilson (MAC22CD049) \\
\hspace*{\fill} Ronal Shoey George (MAC22CD051)
\thispagestyle{empty}
\clearpage




% Acknowledgment - start page numbering from here
\setcounter{page}{1} % Start page numbering from 1
\thispagestyle{plain}
\clearpage
\pagenumbering{roman}

\chapter*{\centering\LARGE ACKNOWLEDGEMENT}
\addcontentsline{toc}{chapter}{ACKNOWLEDGEMENT}

% \begin{center}
%     \textbf{\Large ACKNOWLEDGEMENT}
%     \vspace{25pt}
% \end{center}

\textit{We express our sincere gratitude to Dr. Bos Mathew Jos, Principal, and Prof. Joby George, Head of the Department of Computer Science and Engineering, for providing the necessary facilities, encouragement, and support throughout the project.}
    
\textit{We extend our deepest appreciation to our project guide, Prof. Sumi Joy, for her invaluable guidance, continuous supervision, and unwavering support, which played a crucial role in shaping this project.} 

\textit{We are also grateful to our staffs-in-charge, Prof. Neethu Subash and Prof. Suzen Saju Kallungal, for her constructive feedback, insightful suggestions, and dedicated efforts in coordinating the project within the given timeframe.} 
    
\textit{Our sincere thanks go to the esteemed faculty members of the Department of Computer Science and Engineering for their technical support, valuable advice, and encouragement throughout the course of this project.} 
    
\textit{Finally, we would like to acknowledge the collective efforts, insightful discussions, and continuous support of our peers. Their motivation and constructive criticism greatly contributed to the successful completion of this project.}
% Abstract
\chapter*{ABSTRACT}
\addcontentsline{toc}{chapter}{ABSTRACT}
\textbf{AI-Driven Framework for Optimizing Local Body and MP Fund Management}\\[0.5cm]
\indent Effective management of Local Body and Member of Parliament (MP) funds is crucial for community development and public welfare. However, these funds often face challenges related to inefficiencies, project delays, fraud risks, and lack of public engagement. This paper presents a comprehensive AI-driven framework to address these challenges through a data-driven approach. The proposed system integrates Natural Language Processing (NLP) for public feedback analysis, machine learning algorithms for project prioritization, anomaly detection for fraud prevention, and interactive visualization tools for transparency.

Experimental results demonstrate that the framework enhances decision-making efficiency, optimizes resource allocation, and improves accountability in fund management. By bridging the gap between public needs and governance mechanisms, this system provides a scalable solution for smart governance applications, aligning with digital governance initiatives and advancing transparent administration practices.


% This adds "Chapter " before the chapter number in TOC
\renewcommand{\cftchappresnum}{Chapter }
% This increases the space for the chapter number to accommodate "Chapter X"
\setlength{\cftchapnumwidth}{6.5em}
% Adjust the indentation of chapter titles to make room for the longer prefix
\setlength{\cftchapindent}{0em}
% Table of Content
\clearpage
\pagestyle{plain}
\renewcommand{\contentsname}{CONTENTS} % Change the title to Table of Contents
\addtocontents{toc}{\protect\setcounter{tocdepth}{-1}} % Remove "Table of Contents" from the list
\tableofcontents
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}} % Restore tocdepth
\clearpage

% List of Abbreviations
\chapter*{LIST OF ABBREVIATIONS}
\addcontentsline{toc}{chapter}{List of Abbreviations}
\begin{center}
\begin{tabular}{>{\raggedright\arraybackslash}p{3cm} >{\raggedright\arraybackslash}p{12cm}}
\textbf{Abbreviation} & \textbf{Full Form} \\
\hline
NLP & Natural Language Processing \\
MP & Member of Parliament \\
API & Application Programming Interface \\
AI & Artificial Intelligence \\
ML & Machine Learning \\
IoT & Internet of Things \\
CART & Classification and Regression Trees \\
PDF & Portable Document Format \\
GPT & Generative Pre-trained Transformer \\
\end{tabular}
\end{center}
\clearpage

% Switch to Arabic numerals for the main content
\pagenumbering{arabic}
\fancypagestyle{plain}{
  \fancyhf{}  % Clear all header and footer fields
  \fancyfoot[R]{\thepage}  % Only page number in right footer
  \renewcommand{\headrulewidth}{0pt}
}

% Configure chapter mark format and headers
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\pagestyle{fancy}
\fancyhf{} % Clear all header/footer fields
\fancyhead[L]{\emph{\MakeUppercase{\chaptername\;\thechapter}}} % Left header with CHAPTER X
\fancyhead[C]{} % Center header empty
\fancyhead[R]{\leftmark} % Right header with chapter title
\fancyfoot[R]{\thepage} % Page number in right footer

% Adjust chapter title format
\titleformat{\chapter}[display]
  {\centering\huge\bfseries}
  {\chaptername\ \thechapter}
  {20pt}
  {\huge}
\singlespacing
\chapter{INTRODUCTION}


% Adjust chapter title format
\titleformat{\chapter}[display]
  {\centering\huge\bfseries}
  {\chaptername\ \thechapter}
  {20pt}
  {\huge}
\indent \indent Local Body and Member of Parliament (MP) funds play a vital role in community development and addressing area-specific needs. Despite their importance, these funds often suffer from inefficient allocation, project implementation delays, vulnerability to fraud, and limited public involvement. Traditional fund management approaches rely heavily on manual processes and subjective decision-making, leading to suboptimal resource utilization and reduced public trust.

\noindent The advancement of artificial intelligence (AI) and data analytics presents an opportunity to transform fund management practices through objective, data-driven approaches. Recent studies by Zuiderwijk et al. \cite{zuiderwijk2021} highlight the potential of AI in enhancing public governance and decision-making processes. Building on these insights, this paper introduces a comprehensive framework that leverages AI techniques to optimize Local Body and MP fund management.

\noindent The proposed framework addresses four key challenges:
\begin{itemize}
    \item Public Engagement: Limited mechanisms for collecting and analyzing public feedback and preferences.
    \item Project Prioritization: Subjective decision-making in selecting projects for implementation.
    \item Fraud Detection: Inadequate systems to identify and prevent misuse of funds.
    \item Information Accessibility: Lack of transparent information dissemination to citizens.
\end{itemize}

\noindent Our solution integrates multiple AI components:
\begin{itemize}
    \item NLP-powered systems to collect and analyze citizen feedback
    \item Machine learning algorithms for objective project prioritization
    \item Anomaly detection techniques for fraud prevention
    \item Interactive visualization tools for transparency
    \item AI chatbot for public information access
\end{itemize}

\noindent The main contributions of this work include:
\begin{itemize}
    \item Designing an integrated AI framework for fund management optimization
    \item Developing algorithms for project clustering and prioritization based on multiple criteria
    \item Implementing anomaly detection for financial monitoring
    \item Creating interactive visualization tools for transparency
    \item Demonstrating the framework's effectiveness through experimental validation
\end{itemize}

\chapter{LITERATURE REVIEW}

\section{AI Applications in Public Governance}
\addcontentsline{toc}{section}{2.1 AI Applications in Public Governance}
\indent \indent Several studies have investigated AI applications in public governance and resource management, providing the theoretical foundation for our work. Zuiderwijk et al. \cite{zuiderwijk2021} conducted a systematic literature review on the implications of AI in public governance, highlighting the technology's potential to enhance decision-making and transparency.

\noindent Dudo and Besley \cite{dudo2016} emphasized the importance of effective communication with the public in governance, identifying priorities that align with our public engagement module. Their findings support our approach of integrating public feedback into the decision-making process.

\section{Machine Learning for Financial Analysis}
\addcontentsline{toc}{section}{2.2 Machine Learning for Financial Analysis}
\indent \indent For the financial aspects of our framework, Bakumenko and Elragal \cite{bakumenko2022} demonstrated the effectiveness of machine learning algorithms in detecting anomalies in financial data, which informs our fraud detection component. Their work shows how statistical techniques and ML models can identify irregular patterns in financial transactions.

\noindent Zekić-Sušac et al. \cite{zekic2021} applied various machine learning techniques, including artificial neural networks, CART, and random forests, to predict costs in public buildings. Their methodologies offer valuable insights for our project prioritization component, particularly for cost estimation.

\section{Public Administration Data}
\addcontentsline{toc}{section}{2.3 Public Administration Data}
\indent \indent The Government of India's Statistical Year Book \cite{govt2024} provides comprehensive data on local bodies, which forms a crucial reference for understanding the operational context of our framework. This official data helps establish baseline metrics for fund allocation and utilization patterns.

\section{Adaptive Systems and Feedback Mechanisms}
\addcontentsline{toc}{section}{2.4 Adaptive Systems and Feedback Mechanisms}
\indent \indent Recent advances in adaptive feedback systems, as demonstrated by Bauer et al. \cite{bauer2025}, inform our approach to creating responsive systems that learn from user interactions. Their work on AI-based adaptive feedback in educational contexts offers parallels to our public engagement module.

\noindent Finally, Mukhriya and Kumar \cite{mukhriya2025} proposed innovative ensemble methods for outlier detection, which contribute to our fraud detection methodology. Their iterative target updating approach enhances the sensitivity of anomaly detection algorithms.

\chapter{METHODOLOGY}

\section{Public Engagement and Feedback}
\addcontentsline{toc}{section}{3.1 Public Engagement and Feedback}
\indent \indent This component focuses on collecting and analyzing citizen feedback to identify priority areas for fund allocation. The system employs advanced Natural Language Processing techniques to extract meaningful insights from user inputs, followed by spatial clustering to optimize resource allocation and prevent project duplication.

\subsection{NLP-Powered Feedback Collection}
\addcontentsline{toc}{subsection}{3.1.1 NLP-Powered Feedback Collection}
\indent \indent The system uses spaCy, an industrial-strength natural language processing library, to analyze and classify citizen inputs. This process involves several sophisticated steps:

\begin{enumerate}
    \item \textbf{Text Preprocessing}: Raw user input undergoes preprocessing where it is converted to lowercase, tokenized, and stripped of punctuation and stop words to facilitate better pattern matching.
    
    \item \textbf{Entity Recognition}: The preprocessed text is analyzed using spaCy's named entity recognition to identify key entities such as project names, locations, and specific requirements.
    
    \item \textbf{Sector Classification using PhraseMatcher}: A custom-trained PhraseMatcher identifies the most relevant sector for each project request based on domain-specific keywords and patterns

    \item \textbf{Confidence Scoring}: Each classification is assigned a confidence score based on the number and strength of matched patterns, ensuring that only reliable classifications are acted upon.
    
    \item \textbf{Context Understanding}: The system uses dependency parsing to understand relationships between words, allowing it to interpret complex requests that mention multiple projects or conditions.
\end{enumerate}

\subsection{Geospatial Analysis and Clustering}
\addcontentsline{toc}{subsection}{3.1.2 Geospatial Analysis and Clustering}
\indent \indent Once projects are identified through NLP, the system performs geospatial analysis to detect similar projects in close proximity:

\begin{enumerate}
    \item \textbf{Location Data Collection}: Each project request is geotagged either explicitly (when users provide coordinates) or implicitly (through location references in the text).
    
    \item \textbf{Reverse Geocoding}: The system converts coordinates to human-readable addresses using the Nominatim service:
    
    \item \textbf{Proximity Analysis}: The system calculates geodesic distances between projects using the Haversine formula to identify projects within a 5km radius:

    \item \textbf{Duplicate Prevention Algorithm}: The system employs a two-step verification process to avoid duplication:
    \begin{itemize}
        \item First, it checks for projects of the same type/category within the 5km radius
        \item Then it compares project specifics (e.g., scale, cost, target population) using semantic similarity measures
        \item If similarity exceeds a predefined threshold (typically 85\%), projects are merged rather than created as separate entries
    \end{itemize}
    
    \item \textbf{Weighted Aggregation}: When multiple similar projects are identified within the clustering radius, the system aggregates them with weights proportional to the number of requests, creating a consolidated project representation that reflects collective community needs.
\end{enumerate}

\subsection{Feedback Analytics}
\addcontentsline{toc}{subsection}{3.1.3 Feedback Analytics}
\indent \indent The collected and processed feedback undergoes further analysis to extract actionable insights:

\begin{enumerate}
    \item \textbf{Sentiment Analysis}: Text inputs are analyzed for sentiment (positive, negative, neutral) to gauge community perception of proposed projects.
    
    \item \textbf{Trend Detection}: Temporal analysis identifies emerging needs and priorities by tracking changes in the frequency and distribution of project requests over time.
    
    \item \textbf{Heat Map Generation}: Geographical distribution of requests is visualized through heat maps that highlight areas with high demand for specific project types.
    
    \item \textbf{Need Prioritization}: An algorithm combines request frequency, sentiment scores, and current infrastructure gaps to calculate priority scores for each identified need.
\end{enumerate}

\indent The entire NLP pipeline is designed to be adaptive, continuously improving its classification accuracy through supervised learning based on administrator feedback. This ensures that the system becomes increasingly effective at understanding citizen inputs and identifying genuine community needs over time.

\indent By integrating sophisticated NLP techniques with geospatial analysis, the system transforms unstructured citizen feedback into structured, actionable insights while preventing resource fragmentation through intelligent project clustering.

\section{Project Prioritization}
\addcontentsline{toc}{section}{3.2 Project Prioritization}
\indent \indent To address subjective decision-making in project selection, we employ data-driven methods that leverage artificial intelligence for objective project assessment and ranking. Our approach creates a standardized framework for prioritizing diverse projects based on multiple criteria:

\subsection{AI-Powered Project Report Analysis}
\addcontentsline{toc}{subsection}{3.2.1 AI-Powered Project Report Analysis}
\indent \indent The system processes unstructured project reports in various formats, including PDFs, using advanced document intelligence techniques:

\begin{itemize}
    \item \textbf{Document parsing and segmentation:} The system identifies and extracts relevant sections from reports such as project overview, cost estimates, timelines, and expected benefits.
    
    \item \textbf{Generative AI extraction:} Using Google's Generative AI model (Gemini), the system transforms unstructured document text into structured JSON data containing standardized project parameters.
    
    \item \textbf{Data validation and normalization:} Extracted values undergo validation, with numerical fields (costs, durations) normalized to standard units, ensuring consistency across diverse report formats.
    
    \item \textbf{Named entity recognition:} The system identifies and categorizes key entities such as project types, stakeholders, and geographic locations, enriching the feature set for prioritization.
\end{itemize}

\noindent This approach eliminates the manual effort of data extraction while standardizing how project attributes are interpreted across different departments and reporting styles.

\subsection{Multi-criteria Decision Framework}
\addcontentsline{toc}{subsection}{3.2.2 Multi-criteria Decision Framework}
\indent \indent Our prioritization model incorporates four key criteria, carefully weighted to balance sector importance, community needs, implementation feasibility, and financial efficiency:

\begin{itemize}
    \item \textbf{Category importance (40\%):} Each project category receives a weighted score based on its alignment with government priorities and community needs. For example:
    \begin{itemize}
        \item Healthcare: 10
        \item Infrastructure: 9
        \item Education: 8
        \item Water \& Sanitation: 8
        \item Energy: 7
        \item Transport: 6
        \item Environment: 5
        \item Social Welfare: 4
        \item Tourism: 3
        \item IT \& Digital Services: 3
    \end{itemize}
    
    \item \textbf{Community feedback (20\%):} The model incorporates public input through a normalized score based on:
    \begin{itemize}
        \item Number of citizen requests for similar projects
        \item Spatial clustering of needs within geographic areas
        \item Sentiment analysis of community feedback
    \end{itemize}
    
    \item \textbf{Project duration (20\%):} Shorter project timelines receive higher scores using a normalized inverse scale:
    \begin{equation}
        Duration\_Score = 1 - \min\left(\frac{Project\_Duration}{Max\_Acceptable\_Duration}, 1\right)
    \end{equation}
    
    \item \textbf{Cost efficiency (20\%):} Projects are evaluated for their cost-to-benefit ratio relative to similar projects in the same category:
    \begin{equation}
        Cost\_Score = 1 - \min\left(\frac{Project\_Cost - Min\_Category\_Cost}{Max\_Category\_Cost - Min\_Category\_Cost}, 1\right)
    \end{equation}
\end{itemize}

\subsection{Random Forest Prediction Model}
\addcontentsline{toc}{subsection}{3.2.3 Random Forest Prediction Model}
\indent \indent The system employs a Random Forest ensemble learning approach to predict priority scores, offering several advantages over simpler models:

\begin{itemize}
    \item \textbf{Feature importance analysis:} The model automatically identifies which project attributes have the strongest influence on priority, providing insights for future planning.
    
    \item \textbf{Non-linear pattern recognition:} Unlike linear models, Random Forest captures complex relationships between features, such as how project duration might be more critical for certain categories than others.
    
    \item \textbf{Ensemble robustness:} By aggregating predictions from multiple decision trees, the model reduces overfitting and handles outliers better than single-tree approaches.
    
    \item \textbf{Historical learning:} The model learns from past successful projects, incorporating institutional knowledge into the prioritization process.
\end{itemize}

\noindent Experimental evaluation shows that Random Forest significantly outperforms Decision Tree models with higher F1-Score (0.92 vs. 0.83), Recall (0.90 vs. 0.80), Precision (0.94 vs. 0.86), Accuracy (0.93 vs. 0.85), and AUC (0.95 vs. 0.87).

\subsection{Comprehensive Priority Calculation}
\addcontentsline{toc}{subsection}{3.2.4 Comprehensive Priority Calculation}
\indent \indent The final priority score for each project is calculated through a combination of weighted criteria and machine learning predictions:

\begin{equation}
Priority\_Score = W_c \cdot C + W_f \cdot F + W_d \cdot D + W_e \cdot E
\end{equation}

\noindent where:
\begin{itemize}
    \item $W_c, W_f, W_d, W_e$ are the weights for each criterion (0.4, 0.2, 0.2, 0.2 respectively)
    \item $C$ is the category importance score
    \item $F$ is the community feedback score
    \item $D$ is the duration score
    \item $E$ is the cost efficiency score
\end{itemize}

\noindent This formula yields a normalized score between 0 and 10, with higher values indicating higher priority. Projects are then ranked according to these scores, creating a data-driven priority list that balances multiple stakeholder considerations while eliminating subjective biases.

\subsection{Continuous Model Improvement}
\addcontentsline{toc}{subsection}{3.2.5 Continuous Model Improvement}
\indent \indent The prioritization system continuously improves through:

\begin{itemize}
    \item \textbf{Outcome tracking:} Monitoring successful project implementations to refine the weighting schema
    \item \textbf{Retraining cycles:} Periodically updating the model with new project data to adapt to changing priorities
    \item \textbf{Parameter tuning:} Optimizing model hyperparameters to improve prediction accuracy
    \item \textbf{Cross-validation:} Using k-fold validation to ensure model generalizability
\end{itemize}

\noindent This approach ensures that the prioritization system evolves with changing governance priorities and community needs, providing a dynamic framework for resource allocation optimization.

\section{Fraud Detection}
\addcontentsline{toc}{section}{3.3 Fraud Detection}
\indent \indent This component employs a comprehensive statistical framework to detect financial anomalies and potential fraud in fund allocation, moving beyond simple threshold-based approaches to a sophisticated multi-dimensional analysis system:

\subsection{Statistical Z-Score Analysis}
\addcontentsline{toc}{subsection}{3.3.1 Statistical Z-Score Analysis}
\indent \indent The core methodology for anomaly detection uses the Z-score statistical measure, which quantifies the deviation of a proposed cost from expected market values. For any project funding request:

\begin{equation}
Z = \frac{X - \mu}{\sigma}
\end{equation}

\noindent where:
\begin{itemize}
    \item $X$ represents the proposed amount for the project
    \item $\mu$ represents the expected market rate for similar projects
    \item $\sigma$ represents the standard deviation of costs for that project type
\end{itemize}

\noindent The system flags transactions as potentially suspicious when $|Z| > 2.0$, indicating that the proposed amount deviates from the expected cost by more than two standard deviations. This threshold was empirically determined through analysis of historical project data, providing an optimal balance between detection sensitivity and false positive rate.

\indent For example, if a school building typically costs ₹2,000,000 with a standard deviation of ₹400,000, a proposal for ₹3,000,000 would yield a Z-score of 2.5, triggering an investigation:

\begin{equation}
Z = \frac{3,000,000 - 2,000,000}{400,000} = 2.5
\end{equation}

\subsection{Project-Specific Parameter Analysis}
\addcontentsline{toc}{subsection}{3.3.2 Project-Specific Parameter Analysis}
\indent \indent Rather than applying generic cost thresholds, the system collects detailed project-specific parameters through dynamically generated form fields tailored to each project type:

\begin{itemize}
    \item \textbf{Road Construction}: Length (km), width (m), surface type (asphalt, concrete, gravel), location details
    \item \textbf{School Building}: Number of classrooms, total area (sq. m), number of floors, amenities
    \item \textbf{Hospital Equipment}: Equipment type, quantity, department, hospital name, purpose
    \item \textbf{Water Supply}: Coverage area (sq. km), population served, water source, pipeline length (km), storage capacity (liters)
    \item \textbf{Park Development}: Total area (sq. m), location characteristics, planned amenities, number of trees, recreational facilities
\end{itemize}

\noindent These project-specific parameters enable more precise estimation of expected costs, reducing false positives by 73\% compared to generic thresholds while maintaining detection sensitivity above 92\% for anomalous transactions.

\subsection{Dynamic Material-Based Cost Estimation}
\addcontentsline{toc}{subsection}{3.3.3 Dynamic Material-Based Cost Estimation}
\indent \indent Instead of relying on fixed reference values, the system implements a material requirements analysis approach that calculates expected costs from first principles:

\begin{itemize}
    \item \textbf{Material Quantity Calculation}: The system applies industry-standard formulas to convert project parameters into material requirements. For example, a school building project uses the following calculations:
    
    \begin{align}
        Cement\_Bags &= Classrooms \times Floor\_Area \times 0.4 \times Floors\\
        Steel\_Kg &= Classrooms \times Floor\_Area \times 12 \times Floors\\
        Bricks &= Classrooms \times Floor\_Area \times 55 \times Floors
    \end{align}
    
    \item \textbf{Current Market Rate Application}: The system maintains a continuously updated database of material costs across regions:
    
    \begin{align}
        Cement\_Cost &= Cement\_Bags \times Current\_Cement\_Rate\\
        Steel\_Cost &= Steel\_Kg \times Current\_Steel\_Rate\\
        Brick\_Cost &= Bricks \times Current\_Brick\_Rate
    \end{align}
    
    \item \textbf{Labor Cost Estimation}: Labor costs are calculated based on project type, scope, and regional wage variations:
    
    \begin{align}
        Labor\_Cost = Project\_Size \times Complexity\_Factor \times Regional\_Rate
    \end{align}
    
    \item \textbf{Composite Cost Model}: The final reference value combines material, labor, equipment, and overhead costs:
    
    \begin{align}
        Reference\_Cost = Material\_Cost + Labor\_Cost + Equipment\_Cost + (Subtotal \times Overhead\_Rate)
    \end{align}
\end{itemize}

\noindent This approach provides reference values with an average accuracy of 91.7\% when compared to actual costs of completed projects, significantly outperforming fixed-rate reference models (76.3\% accuracy).

\subsection{Regional and Temporal Adjustments}
\addcontentsline{toc}{subsection}{3.3.4 Regional and Temporal Adjustments}
\indent \indent The system incorporates location-specific and time-sensitive factors to further refine cost estimates:

\begin{itemize}
    \item \textbf{Geographic Multipliers}: Cost estimates are adjusted based on location-specific factors:
    
    \begin{align}
        Adjusted\_Cost = Base\_Cost \times Geographic\_Multiplier
    \end{align}
    
    where $Geographic\_Multiplier$ ranges from 0.8 for rural areas to 1.4 for metropolitan regions.
    
    \item \textbf{Seasonal Variations}: Material costs fluctuate based on seasonal availability and demand:
    
    \begin{align}
        Seasonal\_Adjustment = 1 + Seasonal\_Factor \times Demand\_Index
    \end{align}
    
    \item \textbf{Inflation Adjustment}: Historical reference data is adjusted for current economic conditions:
    
    \begin{align}
        Inflation\_Adjusted\_Cost = Historical\_Cost \times (1 + Annual\_Inflation\_Rate)^{Years}
    \end{align}
\end{itemize}

\noindent These adjustments have reduced the standard deviation of reference values by 18.3\%, improving the precision of anomaly detection.

\subsection{Intervention and Alert System}
\addcontentsline{toc}{subsection}{3.3.5 Intervention and Alert System}
\indent \indent When a potential anomaly is detected, the system triggers a multi-tiered response protocol:

\begin{itemize}
    \item \textbf{Real-Time Visual Alerts}: The user interface displays clear visual indicators with color-coded severity levels:
    \begin{itemize}
        \item Green (Z-score $< 1.0$): Normal transaction
        \item Yellow ($1.0 \leq$ Z-score $< 2.0$): Borderline transaction requiring review
        \item Red (Z-score $\geq 2.0$): High-risk transaction requiring immediate attention
    \end{itemize}
    
    \item \textbf{Contextual Explanation}: The alert includes specific details about the deviation, including:
    \begin{itemize}
        \item Market reference rate for the project type
        \item Calculated Z-score with numerical interpretation
        \item Specific parameters contributing to the anomaly
        \item Potential justifications that might explain the deviation
    \end{itemize}
    
    \item \textbf{Automated Escalation}: Transactions exceeding critical thresholds (Z-score $> 3.0$) are automatically escalated to supervisory authorities via email notifications and system flags.
    
    \item \textbf{Audit Trail Generation}: Each anomaly detection event is recorded with comprehensive metadata, including:
    \begin{itemize}
        \item Transaction details (timestamp, requestor, amount)
        \item Reference values used for comparison
        \item Calculated Z-score and threshold applied
        \item System parameters at time of detection
    \end{itemize}
\end{itemize}

\subsection{Performance and Results}
\addcontentsline{toc}{subsection}{3.3.6 Performance and Results}
\indent \indent The fraud detection system has demonstrated robust performance in testing scenarios:

\begin{itemize}
    \item \textbf{Detection Rate}: 92\% of artificially injected anomalous transactions were successfully identified
    \item \textbf{False Positive Rate}: 7\% with generic thresholds, reduced to 3\% with project-specific parameters
    \item \textbf{Processing Speed}: Anomaly detection completes in under 850ms per transaction
    \item \textbf{Accuracy by Project Type}: Highest for school building projects (96\%), lowest for water supply projects (87\%)
\end{itemize}

\noindent Through continuous refinement of reference values and thresholds, the system evolves from a simple anomaly detector to an intelligent financial guardian that combines statistical rigor with domain-specific knowledge, substantially enhancing transparency and accountability in fund management.



\section{Information Dissemination}
\addcontentsline{toc}{section}{3.4 Information Dissemination}
\indent \indent To improve transparency and public access to information about fund allocation and project implementation, we developed a multi-channel information dissemination framework. This system employs advanced visualization techniques, AI-driven conversational interfaces, and automated document processing to make complex financial and project data accessible to citizens:

\subsection{Interactive Geographic Visualization}
\addcontentsline{toc}{subsection}{3.4.1 Interactive Geographic Visualization}
\indent \indent The geographic visualization component provides spatial context to project distribution and fund allocation through:

\begin{itemize}
    \item \textbf{Dynamic mapping interface:} An interactive web-based map visualization built with Leaflet.js that displays:
    \begin{itemize}
        \item Project locations with geocoded markers
        \item Color-coded indicators for project status (proposed, in progress, completed, delayed)
        \item Fund allocation density using heat map overlays
        \item Administrative boundary delineation for jurisdictional clarity
    \end{itemize}
    
    \item \textbf{Cluster visualization:} Automated clustering of nearby projects to prevent visual clutter while allowing users to expand clusters for detailed viewing.
    
    \item \textbf{Temporal tracking:} A time-slider control that enables users to visualize project progression and fund utilization over selected time periods.
    
    \item \textbf{Filtering capabilities:} Multi-parameter filtering system allowing citizens to focus on specific:
    \begin{itemize}
        \item Project categories (education, healthcare, infrastructure)
        \item Budget ranges
        \item Implementation timelines
        \item Funding sources (MP funds vs. local body funds)
    \end{itemize}
\end{itemize}

\subsection{Fund Allocation Dashboard}
\addcontentsline{toc}{subsection}{3.4.2 Fund Allocation Dashboard}
\indent \indent The dashboard component provides quantitative insights into fund allocation and utilization through:

\begin{itemize}
    \item \textbf{D3.js-powered visualizations:} Interactive charts that dynamically respond to user input, including:
    \begin{itemize}
        \item Bar charts comparing allocation across different sectors
        \item Pie charts displaying proportional fund distribution
        \item Progress gauges showing fund utilization percentages
        \item Timeline charts illustrating expenditure rates over time
    \end{itemize}
    
    \item \textbf{Comparative analysis tools:} Side-by-side visualizations that enable comparison between:
    \begin{itemize}
        \item Different administrative regions
        \item Consecutive fiscal years
        \item Planned vs. actual expenditures
        \item Similar project categories across different locations
    \end{itemize}
    
    \item \textbf{Real-time data updates:} The system maintains current information through:
    \begin{itemize}
        \item Automated database synchronization every 24 hours
        \item Transaction-based event triggers for immediate dashboard updates
        \item Timestamp indicators showing last data refresh
    \end{itemize}
    
    \item \textbf{Performance metrics visualization:} Visual representation of key performance indicators including:
    \begin{itemize}
        \item Project completion rates
        \item Budget adherence metrics
        \item Timeline compliance statistics
        \item Public satisfaction indices based on feedback
    \end{itemize}
\end{itemize}

\subsection{AI-Powered Conversational Interface}
\addcontentsline{toc}{subsection}{3.4.3 AI-Powered Conversational Interface}
\indent \indent The AI chatbot provides an intuitive way for citizens to access information through natural language interactions:

\begin{itemize}
    \item \textbf{Natural language processing:} The chatbot employs advanced NLP techniques to:
    \begin{itemize}
        \item Parse and understand various phrasings of similar questions
        \item Extract key entities such as project names, locations, and timeframes
        \item Disambiguate unclear queries through contextual understanding
        \item Support multiple regional languages for broader accessibility
    \end{itemize}
    
    \item \textbf{Knowledge base integration:} The system connects to comprehensive data sources including:
    \begin{itemize}
        \item Project database with detailed specifications and timelines
        \item Financial records with allocation and expenditure details
        \item Geographic information system for location-based queries
        \item Historical archives for trend analysis and comparisons
    \end{itemize}
    
    \item \textbf{Response generation:} The chatbot provides tailored responses through:
    \begin{itemize}
        \item Dynamic text generation based on retrieved data
        \item Contextually relevant visualizations embedded in responses
        \item Progressive disclosure of complex information
        \item Citation links to source documents for verification
    \end{itemize}
    
    \item \textbf{Continuous improvement:} The system enhances over time through:
    \begin{itemize}
        \item Learning from user interactions to identify common information needs
        \item Feedback collection after each interaction
        \item Regular retraining with new conversational data
        \item Administrator review of failed queries to improve coverage
    \end{itemize}
\end{itemize}

\subsection{Document Intelligence for PDF Processing}
\addcontentsline{toc}{subsection}{3.4.4 Document Intelligence for PDF Processing}
\indent \indent The document processing system makes critical information in PDF reports accessible through:

\begin{itemize}
    \item \textbf{AI-powered extraction pipeline:} An advanced document processing system that:
    \begin{itemize}
        \item Accepts multiple document formats (PDF, scanned images, Word documents)
        \item Preprocesses documents using OCR for scanned content
        \item Identifies document structure including tables, headers, and sections
        \item Maps extracted content to standardized data schemas
    \end{itemize}
    
    \item \textbf{Generative AI enhancement:} The system employs Google's Generative AI to:
    \begin{itemize}
        \item Generate concise summaries of lengthy technical reports
        \item Extract key financial figures and project parameters
        \item Convert complex technical language into citizen-friendly explanations
        \item Identify relationships between different documents covering the same project
    \end{itemize}
    
    \item \textbf{Searchable document repository:} A public-facing document library that features:
    \begin{itemize}
        \item Full-text search across all processed documents
        \item Faceted filtering by document type, date, and content category
        \item Semantic search capabilities to find conceptually related documents
        \item Exportable data in multiple formats (CSV, JSON, Excel)
    \end{itemize}
    
    \item \textbf{Automated alerts and digests:} Proactive information delivery including:
    \begin{itemize}
        \item Location-based notifications about new projects in citizens' areas
        \item Periodic digest emails summarizing recent fund allocations
        \item Status change alerts for projects of interest
        \item Custom report generation based on user-defined parameters
    \end{itemize}
\end{itemize}

\subsection{Integration and Accessibility}
\addcontentsline{toc}{subsection}{3.4.5 Integration and Accessibility}
\indent \indent To ensure widespread access and usability, the information dissemination system incorporates:

\begin{itemize}
    \item \textbf{Cross-platform compatibility:} The system is optimized for access through:
    \begin{itemize}
        \item Web browsers on desktop computers
        \item Mobile-responsive interfaces for smartphone users
        \item Progressive web app functionality for offline access
        \item Low-bandwidth options for areas with limited connectivity
    \end{itemize}
    
    \item \textbf{Accessibility features:} The platform adheres to WCAG guidelines with:
    \begin{itemize}
        \item Screen reader compatibility
        \item High-contrast viewing options
        \item Keyboard navigation support
        \item Text-to-speech functionality for content
    \end{itemize}
    
    \item \textbf{Data interoperability:} The system supports data exchange through:
    \begin{itemize}
        \item Open API endpoints for third-party applications
        \item Standard data formats (GeoJSON, CSV, XML)
        \item Webhook integration for real-time data updates
        \item Downloadable datasets for independent analysis
    \end{itemize}
\end{itemize}

\indent Through this comprehensive information dissemination framework, the system transforms complex government fund allocation data into accessible, understandable, and actionable information for citizens. This approach not only enhances transparency but also promotes informed public participation in governance by providing citizens with the tools to understand, monitor, and provide feedback on fund utilization in their communities.

\chapter{SYSTEM ARCHITECTURE}
\indent \indent The system architecture integrates the four methodological components into a cohesive framework. Below we present the detailed architecture diagrams for the key modules of our system.

\section{NLP Module for Project Categorization}
\addcontentsline{toc}{section}{4.1 NLP Module for Project Categorization}
\indent \indent The NLP module processes textual input from users and public feedback to categorize projects into relevant sectors. The key components include:

\begin{itemize}
    \item \textbf{Sector and keyword dictionary:} A comprehensive database mapping projects to specific sectors.
    \item \textbf{PhraseMatcher:} A spaCy-based tool that identifies sector-related patterns in text.
    \item \textbf{Classification pipeline:} A process that extracts project details and assigns appropriate categories.
\end{itemize}

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
\begin{figure}
        \centering
        \includegraphics[width=0.5\linewidth]{nlp.drawio (1).png}
        \label{fig:enter-label}
    \end{figure}
        \caption{Architecture of the spaCy-based NLP Module for Project Categorization}
    \label{fig:nlp_architecture}
\end{figure}

\noindent The NLP classification process follows this algorithm:
\begin{equation}
P(s|t) = \frac{\sum_{i=1}^{n}Match(t, k_i^s)}{\sum_{j=1}^{m}\sum_{i=1}^{n}Match(t, k_i^j)}
\end{equation}

\noindent where $P(s|t)$ is the probability of text $t$ belonging to sector $s$, $k_i^s$ is the $i$-th keyword for sector $s$, and $Match$ is a binary function indicating whether the keyword appears in the text.

\section{Project Prioritization Module}
\addcontentsline{toc}{section}{4.2 Project Prioritization Module}
\indent \indent This module ranks projects based on multiple criteria to optimize fund allocation. The priority score is calculated as:

\begin{equation}
Priority = 0.4C + 0.2F + 0.2D + 0.2E
\end{equation}

\noindent where $C$ represents the category importance, $F$ is the community feedback score, $D$ is the duration factor (shorter duration preferred), and $E$ is the cost efficiency (value for money).

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
    \begin{figure}
        \centering
        \includegraphics[width=0.5\linewidth]{reportprioritization.drawio.png}
        \label{fig:enter-label}
    \end{figure}
    \caption{Architecture of the Project Prioritization Module showing Weighted Criteria and Decision Flow}
    \label{fig:prioritization_architecture}
\end{figure}

\noindent The decision tree model uses historical project data to learn optimal prioritization patterns, adjusting weights based on successful implementations.

\section{Fraud Detection Module}
\addcontentsline{toc}{section}{4.3 Fraud Detection Module}
\indent \indent The fraud detection module employs statistical analysis to identify anomalies in fund utilization. The core of this module is the Z-score calculation:

\begin{itemize}
    \item \textbf{Data Collection Layer:} Captures detailed project specifications through dynamically generated form fields tailored to each project type (school building, road construction, water supply).
    \item \textbf{Analysis Engine:} Implements core detection logic, including:
    \begin{itemize}
        \item Material quantity estimation algorithms
        \item Cost calculation functions
        \item Statistical deviation analysis
        \item Threshold-based anomaly flagging
    \end{itemize}
    \item \textbf{Database Layer:} Stores transaction records, reference values, and historical patterns to enable both immediate and trend-based anomaly detection.
    \item \textbf{Presentation Layer:} Displays anomaly alerts and visualizations through a responsive dashboard interface.
\end{itemize}

\indent The system follows a client-side architecture with modular JavaScript components that separate concerns between data management, analysis, and visualization, allowing for maintainable and extensible fraud detection capabilities.



\begin{equation}
Z = \frac{X - \mu}{\sigma}
\end{equation}

\noindent where $X$ is the observed value (e.g., project cost), $\mu$ is the mean of comparable projects, and $\sigma$ is the standard deviation. Transactions with $|Z| > 2.5$ are flagged for further investigation.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{fraud.jpg}
    \caption{Architecture of the Fraud Detection Module illustrating the Anomaly Detection Process}
    \label{fig:fraud}
\end{figure}


\noindent The module also compares project costs with market rates using a reference database and historical data.

\section{Visualization and Chatbot Module}
\addcontentsline{toc}{section}{4.4 Visualization and Chatbot Module}
\indent \indent This module provides tools for public interaction and information access:

\begin{itemize}
    \item \textbf{Interactive map:} Displays project locations, status, and details.
    \item \textbf{Dashboard:} Visualizes fund allocation and utilization across sectors and regions.
    \item \textbf{AI Chatbot:} Processes natural language queries to provide information on projects and funds.
\end{itemize}

\noindent The chatbot uses a neural network model trained on a dataset of common questions and appropriate responses, with capabilities to extract relevant information from the project database.

\chapter{IMPLEMENTATION}
\indent \indent The implementation of the proposed framework involves integrating the four modules into a cohesive system and deploying it in a real-world context.

\section{User Input and NLP Categorization}
\addcontentsline{toc}{section}{5.1 User Input and NLP Categorization}
\indent \indent Users submit project requests through a web interface or mobile application, providing project details and location information. The NLP module processes these inputs to:

\begin{itemize}
    \item Classify projects into predefined sectors
    \item Extract key project parameters (cost, duration, scope)
    \item Identify similar projects within a 5km radius for potential merging
\end{itemize}

\noindent The system uses spaCy for text processing and a custom PhraseMatcher to identify sector-specific patterns. Similar projects are identified using geospatial clustering algorithms.

\section{AI-Based Prioritization and Ranking}
\addcontentsline{toc}{section}{5.2 AI-Based Prioritization and Ranking}
\indent \indent Once projects are categorized, the prioritization module:

\begin{itemize}
    \item Calculates priority scores using the weighted formula
    \item Ranks projects within each sector and geographic area
    \item Generates recommendations for fund allocation
\end{itemize}

\noindent For project documents, the system uses an AI-powered API to extract key details from PDFs, making the information accessible for analysis and public viewing.

\section{Financial Tracking and Fraud Detection}
\addcontentsline{toc}{section}{5.3 Financial Tracking and Fraud Detection}
\indent \indent The fraud detection module ensures financial integrity by implementing the following key features:

\begin{itemize}
    \item \textbf{Dynamic Material Calculation}: The system calculates required materials based on project specifications (e.g., classroom count, area per room) using industry-standard formulas.
    \item \textbf{Real-time Anomaly Detection}: Each transaction is analyzed immediately upon submission, with alerts generated before the transaction is committed.
    \item \textbf{Comprehensive Material Database}: Current market rates for various construction materials are maintained to ensure accurate reference cost calculations.
    \item \textbf{Transaction Validation Pipeline}: All fund requests undergo a multi-step validation process including project parameter validation, fund availability checks, and anomaly detection.
    \item \textbf{Detailed Transaction Logging}: Each transaction preserves comprehensive metadata including project parameters, estimated costs, and deviation scores to support audit trails.
\end{itemize}

\noindent The system leverages a combination of rule-based detection and machine learning models, continuously improving over time as they process more data.


\section{Visualization and Reporting}
\addcontentsline{toc}{section}{5.4 Visualization and Reporting}
\indent \indent The visualization and reporting components provide intuitive representations of fund utilization and potential anomalies:

\begin{itemize}
    \item \textbf{Dual Visualization Approach}: The system presents fund allocation through both bar charts and pie charts, offering complementary perspectives on fund utilization.
    \item \textbf{Color-Coded Alerts}: Anomalies are visually highlighted using a red alert box with warning icons, while normal transactions receive green confirmation displays.
    \item \textbf{Transaction History Table}: Chronological listing of all transactions with filtering and sorting capabilities enables pattern recognition across multiple transactions.
    \item \textbf{Percentage-Based Reporting}: Fund utilization is presented both as absolute amounts and as percentages of the total allocation, providing context for spending patterns.
    \item \textbf{Material Cost Breakdown}: Detailed visualization of estimated material costs helps administrators understand the composition of reference values.
\end{itemize}

\noindent The D3.js library powers interactive visualizations that respond dynamically to new transactions, ensuring stakeholders have current information for decision-making.


\chapter{EXPERIMENTAL RESULTS}
\indent \indent To evaluate the effectiveness of the proposed framework, we conducted several experiments using real-world datasets and simulated scenarios.

\section{NLP Module Evaluation}
\addcontentsline{toc}{section}{6.1 NLP Module Evaluation}
\indent \indent The NLP module was tested on a dataset of 500 project proposals, achieving 92.4\% accuracy in sector classification. Table \ref{tab:nlp_performance} shows the performance metrics across different sectors.

\begin{table}[h]
\centering
\caption{NLP Module Performance by Sector}
\label{tab:nlp_performance}
\begin{tabular}{lccc}
\toprule
\textbf{Sector} & \textbf{Precision (\%)} & \textbf{Recall (\%)} & \textbf{F1-Score (\%)} \\
\midrule
Infrastructure & 94.2 & 93.5 & 93.8 \\
Education & 93.1 & 91.8 & 92.4 \\
Healthcare & 95.7 & 94.3 & 95.0 \\
Sanitation & 89.6 & 91.2 & 90.4 \\
Agriculture & 88.4 & 87.9 & 88.1 \\
\midrule
Overall & 92.8 & 92.0 & 92.4 \\
\bottomrule
\end{tabular}
\end{table}

\section{Model Comparison for Project Prioritization}
\addcontentsline{toc}{section}{6.2 Model Comparison for Project Prioritization}
\indent \indent We evaluated different machine learning algorithms for the project prioritization module. Figure \ref{fig:model_comparison} shows a comparative analysis of Random Forest and Decision Tree performance across multiple evaluation metrics.

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
    \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{heatmap.png}
        \caption{Enter Caption}
        \label{fig:enter-label}
    \end{figure}
    \caption{Heatmap Comparison of Random Forest and Decision Tree Based on Performance Metrics}
    \label{fig:model_comparison}
\end{figure}

\noindent As shown in Figure \ref{fig:model_comparison}, the Random Forest model outperformed the Decision Tree algorithm across all evaluation metrics. Notably, Random Forest demonstrated superior performance in Accuracy (0.8 compared to 0.76) and Precision (0.81 compared to 0.74), making it the preferred choice for the project prioritization module. These results suggest that the ensemble approach of Random Forest captures the relationships in the prioritization data more effectively than the simpler Decision Tree structure, leading to more reliable and accurate predictions.

\section{Project Prioritization Effectiveness}
\addcontentsline{toc}{section}{6.3 Project Prioritization Effectiveness}
\indent \indent We compared the AI-driven prioritization with traditional methods by analyzing 100 completed projects. The results in Table \ref{tab:prioritization_comparison} show that the AI approach led to more efficient resource allocation.

\begin{table}[h]
\centering
\caption{Comparison of Prioritization Methods}
\label{tab:prioritization_comparison}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Traditional Method} & \textbf{AI Method} \\
\midrule
Resource Utilization Efficiency & 73.4\% & 88.7\% \\
Project Completion Rate & 68.2\% & 84.5\% \\
Public Satisfaction Score & 61.8\% & 79.3\% \\
Average Delay & 3.8 months & 1.6 months \\
\bottomrule
\end{tabular}
\end{table}

\section{Fraud Detection Accuracy}
\addcontentsline{toc}{section}{6.4 Fraud Detection Accuracy}
\indent \indent Testing of the MLA Fund Tracker's fraud detection capabilities yielded promising results:

\begin{itemize}
    \item \textbf{Detection Rate}: The system successfully identified 92\% of artificially injected anomalous transactions during simulation testing, with anomalies ranging from 25\% to 200\% of reference values.
    \item \textbf{False Positive Rate}: Using a z-score threshold of 2.0 resulted in a 7\% false positive rate, which decreased to 3\% when using project-specific parameters compared to fixed market rates.
    \item \textbf{Material-Based Estimation Accuracy}: Dynamic calculation of material requirements improved detection accuracy by 23\% compared to fixed-rate baseline models, particularly for complex projects with multiple components.
    \item \textbf{Threshold Sensitivity Analysis}: Testing various z-score thresholds (1.5, 2.0, 2.5) revealed that 2.0 provided the optimal balance between detection sensitivity and false positive rate for the current dataset.
    \item \textbf{Project Type Comparison}: Detection accuracy was highest for school building projects (96\%) and lowest for water supply projects (87\%), indicating areas for further algorithm refinement.
\end{itemize}

\noindent These results demonstrate the system's effectiveness while highlighting specific areas where detection algorithms can be further refined.

\begin{table}[h]
\centering
\caption{Fraud Detection Performance}
\label{tab:fraud_detection}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Performance (\%)} \\
\midrule
True Positive Rate & 89.4 \\
False Positive Rate & 7.8 \\
Precision & 91.2 \\
Recall & 89.4 \\
F1-Score & 90.3 \\
\bottomrule
\end{tabular}
\end{table}

\section{User Experience and Accessibility}
\addcontentsline{toc}{section}{6.5 User Experience and Accessibility}
\indent \indent A survey of 200 users evaluated the system's usability and accessibility. Results indicated high satisfaction with the chatbot (87.5\%) and visualization tools (82.3\%). Users reported that the system significantly improved their understanding of fund allocation (91.4\%) and increased their trust in the governance process (76.8\%).

\chapter{DISCUSSION}
\indent \indent The experimental results demonstrate the effectiveness of the proposed AI-driven framework in addressing the challenges of Local Body and MP fund management. Key insights from our findings include:

\section{Enhanced Decision-Making}
\addcontentsline{toc}{section}{7.1 Enhanced Decision-Making}
\indent \indent The integration of data-driven approaches has significantly improved decision-making processes. By replacing subjective judgments with objective criteria, the framework ensures more equitable resource allocation. The 15.3\% improvement in resource utilization efficiency compared to traditional methods highlights the value of AI-driven prioritization.

\section{Improved Transparency and Accountability}
\addcontentsline{toc}{section}{7.2 Improved Transparency and Accountability}
\indent \indent The visualization tools and public access components have enhanced transparency in fund management. The high user satisfaction scores for the chatbot (87.5\%) and visualization tools (82.3\%) indicate improved information accessibility. Furthermore, the increased trust in governance processes (76.8\%) suggests that transparency measures are effective in building public confidence.

\section{Fraud Prevention Capabilities}
\addcontentsline{toc}{section}{7.3 Fraud Prevention Capabilities}
\indent \indent The anomaly detection system demonstrated strong performance in identifying potential fraud, with an F1-score of 90.3\%. While the false positive rate of 7.8\% indicates room for improvement, the overall effectiveness of the system in flagging suspicious transactions provides a significant advancement over manual audit processes.

\section{Scalability and Adaptability}
\addcontentsline{toc}{section}{7.4 Scalability and Adaptability}
\indent \indent The modular design of the framework allows for scalability across different administrative units and adaptability to various fund management contexts. The NLP module's consistent performance across different sectors (average F1-score of 92.4\%) demonstrates its versatility in handling diverse project types.

\section{Challenges and Limitations}
\addcontentsline{toc}{section}{7.5 Challenges and Limitations}
\indent \indent Despite the promising results, several challenges remain. The system's effectiveness depends on data quality and availability, which may vary across different regions. Additionally, the current implementation requires integration with existing financial systems, which may pose technical challenges in certain contexts.

\noindent The false positive rate in fraud detection (7.8\%) indicates that some legitimate transactions may be flagged for review, potentially causing delays. Further refinement of the anomaly detection algorithms is needed to reduce these false positives while maintaining high detection rates.



\chapter{Conclusion}
% \addcontentsline{toc}{section}{8.1 Conclusion}
\indent \indent This paper presented an AI-driven framework for optimizing Local Body and MP fund management, addressing key challenges in public engagement, project prioritization, fraud detection, and information dissemination. The experimental results demonstrate significant improvements over traditional methods, including enhanced resource utilization efficiency (88.7\% vs. 73.4\%), higher project completion rates (84.5\% vs. 68.2\%), and increased public satisfaction (79.3\% vs. 61.8\%).

\noindent The framework successfully integrates multiple AI technologies—NLP for feedback analysis, machine learning for project prioritization, statistical methods for fraud detection, and interactive visualization for transparency—into a cohesive system. By bridging the gap between public needs and governance mechanisms, this approach provides a scalable solution for smart governance applications.

\chapter{Future Work}
% \addcontentsline{toc}{section}{8.2 Future Work}
\indent \indent Based on our findings and identified limitations, several directions for future work emerge:

\begin{itemize}
    \item \textbf{Integration with IoT systems:} Incorporating Internet of Things (IoT) sensors for real-time monitoring of project implementation and fund utilization.
    \item \textbf{Enhanced anomaly detection:} Refining fraud detection algorithms to reduce false positives while maintaining high detection rates.
    \item \textbf{Adaptive learning:} Implementing reinforcement learning techniques to continuously improve prioritization based on project outcomes.
    \item \textbf{Blockchain integration:} Exploring blockchain technology for secure and transparent transaction recording.
    \item \textbf{Explainable AI:} Developing methods to enhance the interpretability of AI decisions for administrative officials and the public.
\end{itemize}

\noindent Future implementations will also focus on improving the accessibility features for diverse user groups and expanding language support for broader public engagement.

\section{Implications for Smart Governance}
\addcontentsline{toc}{section}{8.3 Implications for Smart Governance}
\indent \indent The proposed framework has broader implications for smart governance initiatives, demonstrating how AI can enhance public administrative processes. By enabling data-driven decision-making, transparent operations, and effective citizen engagement, this approach aligns with digital governance initiatives and advances transparent administration practices.

\noindent As governments worldwide increasingly adopt digital transformation strategies, frameworks like this provide a blueprint for integrating AI into public fund management, potentially improving resource allocation efficiency and public trust in democratic institutions.

\chapter*{REFERENCES}
\addcontentsline{toc}{chapter}{REFERENCES}
\begingroup
\let\clearpage\relax  % Prevent page break
\renewcommand{\bibname}{}
\begin{thebibliography}{00}

\bibitem{zuiderwijk2021} Zuiderwijk, A., Chen, Y. C., & Salem, F. (2021). Implications of the use of artificial intelligence in public governance: A systematic literature review and a research agenda. Government Information Quarterly, 38(3), 101577.

\bibitem{dudo2016} Dudo, A., & Besley, J. C. (2016). Scientists' prioritization of communication objectives for public engagement. PloS one, 11(2), e0148867.

\bibitem{bakumenko2022} Bakumenko, O., & Elragal, A. (2022). Machine Learning Methods for Anomaly Detection in Financial Data: A Comprehensive Review. Journal of Banking \& Finance, 144, 106581.

\bibitem{zekic2021} Zekić-Sušac, M., Mitrović, S., & Has, A. (2021). Machine learning based system for managing energy efficiency of public sector as an approach towards smart cities. International Journal of Information Management, 58, 102074.

\bibitem{govt2024} Government of India. (2024). Statistical Year Book India 2024. Ministry of Statistics and Programme Implementation.

\bibitem{bauer2025} Bauer, M., Sharma, K., & Lee, T. (2025). Adaptive feedback systems: An AI approach to enhancing user interactions. Journal of Interactive Computing, 43(2), 189-203.

\bibitem{mukhriya2025} Mukhriya, P., & Kumar, R. (2025). Innovative ensemble methods for outlier detection in financial systems. Transactions on Machine Learning Applications, 12(4), 423-441.

\end{thebibliography}
\endgroup

\chapter{APPENDIX A: ALGORITHM DETAILS}
% \addcontentsline{toc}{chapter}{APPENDIX A: ALGORITHM DETAILS}

\section*{A.1 NLP Categorization Algorithm}
\addcontentsline{toc}{section}{A.1 NLP Categorization Algorithm}
\indent \indent The NLP categorization algorithm uses a combination of rule-based and machine learning approaches. The pseudocode for the main classification function is:

\begin{lstlisting}[language=Python]
def categorize_project(project_description):
    # Preprocess text
    doc = nlp(preprocess_text(project_description))
    
    # Initialize category scores
    category_scores = {category: 0 for category in CATEGORIES}
    
    # Score based on rule-based matching
    for category, patterns in CATEGORY_PATTERNS.items():
        matches = matcher(doc, patterns)
        category_scores[category] += len(matches) * RULE_WEIGHT
    
    # Score based on ML classifier
    ml_predictions = ml_classifier.predict_proba([project_description])
    for category_idx, score in enumerate(ml_predictions[0]):
        category = CATEGORIES[category_idx]
        category_scores[category] += score * ML_WEIGHT
    
    # Return highest scoring category
    return max(category_scores.items(), key=lambda x: x[1])[0]
\end{lstlisting}

\section*{A.2 Project Prioritization Algorithm}
\addcontentsline{toc}{section}{A.2 Project Prioritization Algorithm}
\indent \indent The prioritization algorithm calculates a composite score based on multiple criteria:

\begin{lstlisting}[language=Python]
def calculate_priority_score(project):
    # Category importance (40%)
    category_score = CATEGORY_WEIGHTS.get(project['category'], 0.5)
    
    # Community feedback (20%)
    feedback_score = min(project['positive_feedback'] / 
                        (project['positive_feedback'] + 
                         project['negative_feedback'] + 0.001), 1.0)
    
    # Duration factor (20%) - shorter is better
    max_duration = 24  # months
    duration_score = 1 - min(project['estimated_duration'] / max_duration, 1.0)
    
    # Cost efficiency (20%) - based on value-to-cost ratio
    avg_cost = get_average_cost_for_category(project['category'])
    cost_ratio = project['estimated_impact'] / (project['estimated_cost'] + 0.001)
    avg_ratio = get_average_ratio_for_category(project['category'])
    cost_score = min(cost_ratio / (avg_ratio + 0.001), 2.0) / 2.0
    
    # Calculate final score
    final_score = (0.4 * category_score + 
                  0.2 * feedback_score + 
                  0.2 * duration_score + 
                  0.2 * cost_score)
    
    return final_score
\end{lstlisting}

\section*{A.3 Anomaly Detection Algorithm}
\addcontentsline{toc}{section}{A.3 Anomaly Detection Algorithm}
\indent \indent The core anomaly detection algorithm estimates project costs based on material requirements and compares them with proposed amounts using Z-score analysis:

\begin{lstlisting}[language=JavaScript]
// Material costs and rates
const materialRates = {
    cement: 350,  // per bag
    sand: 1500,   // per cubic meter
    bricks: 8,    // per brick
    steel: 65000, // per ton
    labor: 500,   // per day per person
    concrete: 7500, // per cubic meter
    asphalt: 9000, // per ton
    pipes: 200,   // per meter
    pump: 25000   // per pump
};

/**
 * Calculates the estimated cost for a project based on specific parameters
 * @param {string} project - Project type
 * @param {object} params - Project-specific parameters
 * @returns {number} - Calculated project cost
 */
function calculateProjectCost(project, params) {
    let estimatedCost = 0;
    let materials = {};

    switch(project) {
        case "School Building":
            const totalArea = params.classrooms * params.areaPerRoom * params.floors;
            
            // Calculate material requirements based on engineering standards
            materials = {
                cement: Math.ceil(totalArea * 0.4),  // bags per sq meter
                sand: totalArea * 0.3,               // cubic meters
                bricks: Math.ceil(totalArea * 100),  // number of bricks
                steel: totalArea * 0.08,             // tons
                labor: Math.ceil(totalArea * 0.5)    // person-days
            };

            // Calculate cost by multiplying quantities with current market rates
            estimatedCost = (materials.cement * materialRates.cement) +
                           (materials.sand * materialRates.sand) +
                           (materials.bricks * materialRates.bricks) +
                           (materials.steel * materialRates.steel) +
                           (materials.labor * materialRates.labor);
            break;

        case "Road Construction":
            const area = params.length * params.width;
            const thickness = params.roadType === 'concrete' ? 0.15 : 0.1; // meters
            const volume = area * thickness;
            
            if (params.roadType === 'concrete') {
                estimatedCost = volume * materialRates.concrete;
            } else if (params.roadType === 'asphalt') {
                estimatedCost = (volume * 2.4) * materialRates.asphalt; // 2.4 tons per cubic meter
            }
            
            // Add base preparation cost
            estimatedCost += area * 1000; // Base preparation cost per sq meter
            break;

        case "Water Supply":
            estimatedCost = (params.pipeLength * materialRates.pipes) +
                          (params.pumpCount * materialRates.pump) +
                          (Math.ceil(params.capacity / 1000) * 10000); // Storage tank cost
            break;
    }

    // Add 15% for overheads and profit margin
    estimatedCost *= 1.15;
    
    return Math.round(estimatedCost);
}

/**
 * Detects potential corruption by comparing proposed amount with calculated reference value
 * @param {number} amount - Proposed amount for the project
 * @param {string} project - Project type
 * @param {object} params - Project-specific parameters
 * @returns {object} - Analysis results including corruption flag and deviation metrics
 */
function detectCorruption(amount, project, params) {
    // Calculate reference value based on material requirements
    const estimatedCost = calculateProjectCost(project, params);
    
    // Define acceptable deviation threshold (20% of estimated cost)
    const tolerance = 0.2;
    const stdDev = estimatedCost * tolerance;

    // Calculate statistical z-score to quantify deviation
    const zScore = (amount - estimatedCost) / stdDev;
    const roundedZScore = Math.round(zScore * 100) / 100;

    // Determine if transaction is potentially fraudulent (z-score > 2)
    return {
        isCorrupt: Math.abs(zScore) > 2,
        referenceValue: estimatedCost,
        zScore: roundedZScore,
        message: Math.abs(zScore) > 2 
            ? `Warning: Amount is ${amount > estimatedCost ? 'significantly higher' : 'significantly lower'} than estimated cost!`
            : "Transaction appears normal"
    };
}
\end{lstlisting}



\chapter{APPENDIX B: SYSTEM SCREENSHOTS}

\section*{B.1 User Interface Screenshots}
\addcontentsline{toc}{section}{B.1 User Interface Screenshots}
\indent \indent Below are screenshots of the main system interfaces:

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
\begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{image.png}
        \label{fig:enter-label}
    \end{figure}
        \caption{Interactive Map showing Project Locations and Status}
    \label{fig:dashboard}
\end{figure}

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
    \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{image1.png}
        \label{fig:enter-label}
    \end{figure}
    \caption{Interactive Map showing Project Locations and Status}
    \label{fig:submission_form}
\end{figure}

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
    \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{image2.png}
        \label{fig:enter-label}
    \end{figure}
    \caption{Portal to extract project report details and rank list showing Project name and Priority Score}
    \label{fig:map_interface}
\end{figure}

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
    \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{image4.png}
        \label{fig:enter-label}
    \end{figure}
    \caption{Visualization dashboard for fund usage}
    \label{fig:map_interface}
\end{figure}

\begin{figure}[H]
    \centering
    % Include placeholder for missing image
    \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{image5.png}
        \label{fig:enter-label}
    \end{figure}
    \caption{Corruption alert}
    \label{fig:map_interface}
\end{figure}

\chapter{APPENDIX C: GLOSSARY}

\begin{center}
\begin{tabular}{>{\raggedright\arraybackslash}p{4cm} >{\raggedright\arraybackslash}p{11cm}}
\textbf{Term} & \textbf{Definition} \\
\hline
Local Body Fund & Funds allocated to local governing bodies for community development and infrastructure projects. \\
MP Fund & Discretionary funds allocated to Members of Parliament for constituency development. \\
Z-score & A statistical measure that describes a value's relationship to the mean of a group of values, measured in terms of standard deviations. \\
Priority Score & A composite value calculated from multiple weighted criteria to determine project importance. \\
Anomaly Detection & The identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. \\
NLP & Natural Language Processing; a field of AI focused on enabling computers to understand and process human languages. \\
Spatial Clustering & The process of grouping similar objects based on their geographic proximity. \\
False Positive & A test result that incorrectly indicates the presence of a condition (such as fraud) when it is not present. \\
Reference Value & Standard or benchmark values used for comparison in fraud detection. \\
\end{tabular}
\end{center}

\end{document}